{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7572869e-ded3-4e35-902f-2c244c50c0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vaishnav M\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/rmisra/news-headlines-dataset-for-sarcasm-detection?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3.30M/3.30M [00:02<00:00, 1.17MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Vaishnav M\\.cache\\kagglehub\\datasets\\rmisra\\news-headlines-dataset-for-sarcasm-detection\\versions\\2\n",
      "                                        article_link  \\\n",
      "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
      "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
      "2  https://local.theonion.com/mom-starting-to-fea...   \n",
      "3  https://politics.theonion.com/boehner-just-wan...   \n",
      "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
      "\n",
      "                                            headline  is_sarcastic  \n",
      "0  former versace store clerk sues over secret 'b...             0  \n",
      "1  the 'roseanne' revival catches up to our thorn...             0  \n",
      "2  mom starting to fear son's web series closest ...             1  \n",
      "3  boehner just wants wife to listen, not come up...             1  \n",
      "4  j.k. rowling wishes snape happy birthday in th...             0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26709 entries, 0 to 26708\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   article_link  26709 non-null  object\n",
      " 1   headline      26709 non-null  object\n",
      " 2   is_sarcastic  26709 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 626.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import kagglehub\n",
    "import json\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"rmisra/news-headlines-dataset-for-sarcasm-detection\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(path + '/Sarcasm_Headlines_Dataset.json', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8658f06a-d154-46fd-bc8f-15815a0abca6",
   "metadata": {},
   "source": [
    "## Define the Cleaning Function\n",
    "\n",
    "We create a function `clean_headline` that applies the following transformations to each headline:\n",
    "- Expands contractions\n",
    "- Removes URLs\n",
    "- Removes non-ASCII characters\n",
    "- Removes special characters (using a regex pattern)\n",
    "- Converts the text to lowercase\n",
    "- Removes punctuation\n",
    "- Trims extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "035e1737-285e-4fe8-930a-1cc8e0f0cbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import contractions\n",
    "\n",
    "def clean_headline(text):\n",
    "    \"\"\"\n",
    "    Clean a news headline by applying several transformations:\n",
    "    1. Expand contractions (e.g., \"can't\" -> \"cannot\").\n",
    "    2. Remove URLs.\n",
    "    3. Remove non-ASCII characters.\n",
    "    4. Remove special characters using a regex pattern.\n",
    "    5. Convert text to lowercase.\n",
    "    6. Remove punctuation.\n",
    "    7. Remove extra spaces.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text, 0\n",
    "\n",
    "    change_count = 0\n",
    "    original = text\n",
    "\n",
    "    # Expand contractions\n",
    "    expanded = contractions.fix(text)\n",
    "    if expanded != text:\n",
    "        change_count += 1\n",
    "    text = expanded\n",
    "    \n",
    "    # Remove URLs\n",
    "    removed_url = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    if removed_url != text:\n",
    "        change_count += 1\n",
    "    text = removed_url\n",
    "    \n",
    "    # Remove non-ASCII characters\n",
    "    non_ascii_removed = text.encode('ascii', 'ignore').decode('utf-8')\n",
    "    if non_ascii_removed != text:\n",
    "        change_count += 1\n",
    "    text = non_ascii_removed\n",
    "    \n",
    "    # Remove special characters (emoticons, symbols, etc.)\n",
    "    regex_pattern = re.compile(\n",
    "        pattern = \"[\"  \n",
    "                  u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                  u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                  u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                  u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                  u\"\\U00002702-\\U000027B0\"\n",
    "                  u\"\\U000024C2-\\U0001F251\"\n",
    "                  u\"\\ufe0f\"                # dingbats\n",
    "                  \"]+\", flags = re.UNICODE)\n",
    "    special_removed = regex_pattern.sub(r'', text)\n",
    "    if special_removed != text:\n",
    "        change_count += 1\n",
    "    text = special_removed\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    lowercased = text.lower()\n",
    "    if lowercased != text:\n",
    "        change_count += 1\n",
    "    text = lowercased\n",
    "    \n",
    "    # Remove punctuation\n",
    "    no_punct = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    if no_punct != text:\n",
    "        change_count += 1\n",
    "    text = no_punct\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    no_extra_spaces = re.sub(r'\\s+', ' ', text).strip()\n",
    "    if no_extra_spaces != text:\n",
    "        change_count += 1\n",
    "    text = no_extra_spaces\n",
    "    \n",
    "    return text, change_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c24de03-906c-4072-9423-e7b93c474e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            headline  \\\n",
      "0  former versace store clerk sues over secret 'b...   \n",
      "1  the 'roseanne' revival catches up to our thorn...   \n",
      "2  mom starting to fear son's web series closest ...   \n",
      "3  boehner just wants wife to listen, not come up...   \n",
      "4  j.k. rowling wishes snape happy birthday in th...   \n",
      "\n",
      "                                    headline_cleaned  num_changes  \n",
      "0  former versace store clerk sues over secret bl...            1  \n",
      "1  the roseanne revival catches up to our thorny ...            1  \n",
      "2  mom starting to fear sons web series closest t...            1  \n",
      "3  boehner just wants wife to listen not come up ...            1  \n",
      "4  jk rowling wishes snape happy birthday in the ...            1  \n"
     ]
    }
   ],
   "source": [
    "# Apply the cleaning function to the 'headline' column\n",
    "df[['headline_cleaned', 'num_changes']] = df['headline'].apply(lambda x: pd.Series(clean_headline(x)))\n",
    "\n",
    "# Display the original and cleaned headlines for comparison\n",
    "print(df[['headline', 'headline_cleaned', 'num_changes']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7065f0-e615-459d-bfef-09f8eb7987e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_changes\n",
       "1    13403\n",
       "0    11042\n",
       "2     2155\n",
       "3      101\n",
       "4        8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['num_changes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ab8287b-3c16-45e4-b37d-3d5da2cecdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('intermediate_files/sarcasm_headlines_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
