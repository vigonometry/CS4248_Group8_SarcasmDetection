{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T14:50:02.683489Z",
     "start_time": "2025-03-09T14:50:02.280169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "from nltk import sentiment\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from textatistic import Textatistic\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ],
   "id": "e2f09d3c920c201",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T14:50:02.689231Z",
     "start_time": "2025-03-09T14:50:02.686822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ],
   "id": "33abb26e5e8ead0c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('vader_lexicon')"
   ],
   "id": "b20785859c42c0a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T15:11:07.916494Z",
     "start_time": "2025-03-09T15:11:05.592889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#nltk\n",
    "# processed_df = pd.read_csv('data/preprocessed.csv',\n",
    "#                            usecols=['headline',\n",
    "#                                     'headline_cleaned',\n",
    "#                                     'tokenized_text_nltk',\n",
    "#                                     'pos_tagged_text_nltk',\n",
    "#                                     'lemmatized_text_nltk',\n",
    "#                                     'is_sarcastic'],\n",
    "#                            converters={'tokenized_text_nltk': literal_eval,\n",
    "#                                        'pos_tagged_text_nltk': literal_eval,\n",
    "#                                        'lemmatized_text_nltk': literal_eval})\n",
    "\n",
    "#spacy\n",
    "processed_df = pd.read_csv('data/preprocessed.csv',\n",
    "                           usecols=['headline',\n",
    "                                    'headline_cleaned',\n",
    "                                    'tokenized_text_spacy',\n",
    "                                    'pos_tagged_text_spacy',\n",
    "                                    'lemmatized_text_spacy',\n",
    "                                    'is_sarcastic'],\n",
    "                           converters={'tokenized_text_spacy': literal_eval,\n",
    "                                       'pos_tagged_text_spacy': literal_eval,\n",
    "                                       'lemmatized_text_spacy': literal_eval})\n",
    "\n",
    "print(processed_df.shape)\n",
    "processed_df.head()\n"
   ],
   "id": "4086f96e1c666388",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26709, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                            headline  is_sarcastic  \\\n",
       "0  former versace store clerk sues over secret 'b...             0   \n",
       "1  the 'roseanne' revival catches up to our thorn...             0   \n",
       "2  mom starting to fear son's web series closest ...             1   \n",
       "3  boehner just wants wife to listen, not come up...             1   \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0   \n",
       "\n",
       "                                    headline_cleaned  \\\n",
       "0  former versace store clerk sues over secret bl...   \n",
       "1  the roseanne revival catches up to our thorny ...   \n",
       "2  mom starting to fear sons web series closest t...   \n",
       "3  boehner just wants wife to listen not come up ...   \n",
       "4  jk rowling wishes snape happy birthday in the ...   \n",
       "\n",
       "                                tokenized_text_spacy  \\\n",
       "0  [former, versace, store, clerk, sues, over, se...   \n",
       "1  [the, roseanne, revival, catches, up, to, our,...   \n",
       "2  [mom, starting, to, fear, sons, web, series, c...   \n",
       "3  [boehner, just, wants, wife, to, listen, not, ...   \n",
       "4  [jk, rowling, wishes, snape, happy, birthday, ...   \n",
       "\n",
       "                               pos_tagged_text_spacy  \\\n",
       "0  [(former, JJ), (versace, NN), (store, NN), (cl...   \n",
       "1  [(the, DT), (roseanne, NNP), (revival, NNP), (...   \n",
       "2  [(mom, NN), (starting, VBG), (to, TO), (fear, ...   \n",
       "3  [(boehner, NN), (just, RB), (wants, VBZ), (wif...   \n",
       "4  [(jk, NNP), (rowling, NNP), (wishes, VBZ), (sn...   \n",
       "\n",
       "                               lemmatized_text_spacy  \n",
       "0  [former, versace, store, clerk, sue, over, sec...  \n",
       "1  [the, roseanne, revival, catch, up, to, our, t...  \n",
       "2  [mom, start, to, fear, son, web, series, close...  \n",
       "3  [boehner, just, want, wife, to, listen, not, c...  \n",
       "4  [jk, rowling, wish, snape, happy, birthday, in...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline_cleaned</th>\n",
       "      <th>tokenized_text_spacy</th>\n",
       "      <th>pos_tagged_text_spacy</th>\n",
       "      <th>lemmatized_text_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "      <td>former versace store clerk sues over secret bl...</td>\n",
       "      <td>[former, versace, store, clerk, sues, over, se...</td>\n",
       "      <td>[(former, JJ), (versace, NN), (store, NN), (cl...</td>\n",
       "      <td>[former, versace, store, clerk, sue, over, sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "      <td>the roseanne revival catches up to our thorny ...</td>\n",
       "      <td>[the, roseanne, revival, catches, up, to, our,...</td>\n",
       "      <td>[(the, DT), (roseanne, NNP), (revival, NNP), (...</td>\n",
       "      <td>[the, roseanne, revival, catch, up, to, our, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "      <td>mom starting to fear sons web series closest t...</td>\n",
       "      <td>[mom, starting, to, fear, sons, web, series, c...</td>\n",
       "      <td>[(mom, NN), (starting, VBG), (to, TO), (fear, ...</td>\n",
       "      <td>[mom, start, to, fear, son, web, series, close...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "      <td>boehner just wants wife to listen not come up ...</td>\n",
       "      <td>[boehner, just, wants, wife, to, listen, not, ...</td>\n",
       "      <td>[(boehner, NN), (just, RB), (wants, VBZ), (wif...</td>\n",
       "      <td>[boehner, just, want, wife, to, listen, not, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "      <td>jk rowling wishes snape happy birthday in the ...</td>\n",
       "      <td>[jk, rowling, wishes, snape, happy, birthday, ...</td>\n",
       "      <td>[(jk, NNP), (rowling, NNP), (wishes, VBZ), (sn...</td>\n",
       "      <td>[jk, rowling, wish, snape, happy, birthday, in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create New Features from Text",
   "id": "3ab5ac2e6170462d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T15:11:08.377154Z",
     "start_time": "2025-03-09T15:11:08.374706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_punctuations(headline):\n",
    "    \"\"\"\n",
    "    Helper function to get punctuation count from headlines\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for punc in string.punctuation:\n",
    "        count += headline.count(punc)\n",
    "    return count"
   ],
   "id": "dd3d1d69b0f6fdc",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T15:11:10.624171Z",
     "start_time": "2025-03-09T15:11:10.617703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_unique_repeated(headline):\n",
    "    \"\"\"\n",
    "    Helper function to get unique and repeated words from sentences\n",
    "    \"\"\"\n",
    "    try:\n",
    "        vec = CountVectorizer(ngram_range=(1, 1), stop_words=None)\n",
    "        bow = vec.fit_transform([headline])\n",
    "\n",
    "        sum_of_words = bow.sum(axis=0)\n",
    "\n",
    "        unigram_freq = [(word, sum_of_words[0, i]) for word, i in vec.vocabulary_.items()]\n",
    "\n",
    "        unigram_freq = pd.DataFrame(unigram_freq, columns=['word', 'freq'])\n",
    "\n",
    "        #number of unique words\n",
    "        num_unique = len(unigram_freq[unigram_freq.freq == 1])\n",
    "        #number of repeated words\n",
    "        num_repeated = len(unigram_freq[unigram_freq.freq > 1])\n",
    "\n",
    "        return [num_unique, num_repeated]\n",
    "    except:\n",
    "        try:\n",
    "        #deals with headlines that only contain stopwords\n",
    "            headline = headline.replace(' ', '')\n",
    "            vec = CountVectorizer(ngram_range=(1, 1), stop_words=None)\n",
    "            bow = vec.fit_transform([headline])\n",
    "\n",
    "            sum_of_words = bow.sum(axis=0)\n",
    "\n",
    "            unigram_freq = [(word, sum_of_words[0, i]) for word, i in vec.vocabulary_.items()]\n",
    "\n",
    "            unigram_freq = pd.DataFrame(unigram_freq, columns=['word', 'freq'])\n",
    "\n",
    "            #number of unique words\n",
    "            num_unique = len(unigram_freq[unigram_freq.freq == 1])\n",
    "            #number of repeated words\n",
    "            num_repeated = len(unigram_freq[unigram_freq.freq > 1])\n",
    "\n",
    "            return [num_unique, num_repeated]\n",
    "        except:\n",
    "            #empty strings\n",
    "            return [0, 0]"
   ],
   "id": "2375960b12f5a83f",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T15:11:12.289397Z",
     "start_time": "2025-03-09T15:11:12.284773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_word_tag_count(text_tag):\n",
    "    \"\"\"\n",
    "    Returns count of parts of speech (POS) tags from text_tag\n",
    "    \"\"\"\n",
    "    noun_count = len([w for w in text_tag if w[1].startswith('NN')])\n",
    "    adjective_count = len([w for w in text_tag if w[1].startswith('JJ')])\n",
    "    verb_count = len([w for w in text_tag if w[1].startswith('VB')])\n",
    "\n",
    "    return [noun_count, adjective_count, verb_count]"
   ],
   "id": "3fb1bfcdace3c605",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T15:11:12.451730Z",
     "start_time": "2025-03-09T15:11:12.448997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def count_regexp_occ(regexp=\"\", text=None):\n",
    "    \"\"\"\n",
    "    Returns count of occurrences of specified Regex pattern\n",
    "    \"\"\"\n",
    "    return len(re.findall(regexp, text))"
   ],
   "id": "8972515341f211a9",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T15:11:12.597937Z",
     "start_time": "2025-03-09T15:11:12.595293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def readability(text):\n",
    "    \"\"\"\n",
    "    Helper function to get readability score of a piece of text.\n",
    "    \"\"\"\n",
    "\n",
    "    #hyphenated words should not have more than 100 characters\n",
    "    text = text.replace('_', ' ')\n",
    "    try:\n",
    "        return Textatistic(text).flesch_score\n",
    "    except:\n",
    "        try:\n",
    "            text += '.'\n",
    "            score = Textatistic(text).flesch_score\n",
    "            return score\n",
    "        except:\n",
    "            return 0\n"
   ],
   "id": "11244311f79e48fa",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T15:11:12.972290Z",
     "start_time": "2025-03-09T15:11:12.969817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sentiment(text):\n",
    "    \"\"\"\n",
    "    Helper function to get sentiment score of a piece of text.\n",
    "    \"\"\"\n",
    "    sentiments = SentimentIntensityAnalyzer()\n",
    "    score = sentiments.polarity_scores(text)['compound']\n",
    "    return score"
   ],
   "id": "ee3aae7c28ad229c",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T15:12:52.441382Z",
     "start_time": "2025-03-09T15:12:52.423312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_features(data):\n",
    "    feature_df = data.copy()\n",
    "\n",
    "    print('Getting Length of headline')\n",
    "    feature_df['headline_length'] = feature_df['headline'].apply(len)\n",
    "\n",
    "    print('Creating Word Features')\n",
    "    # feature_df['num_words'] = feature_df['tokenized_text_nltk'].apply(len)\n",
    "    feature_df['num_words'] = feature_df['tokenized_text_spacy'].apply(len)\n",
    "    #number of words vs length of headline\n",
    "    feature_df['num_words_vs_length'] = np.where(feature_df['headline_length'] > 0, feature_df['num_words'] / feature_df['headline_length'], 0)\n",
    "    #length of headline vs number of words\n",
    "    feature_df['length_vs_num_words'] = np.where(feature_df['num_words'] > 0, feature_df['headline_length'] / feature_df['num_words'], 0)\n",
    "\n",
    "    #stopwords\n",
    "    print('Creating Stopword features')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # feature_df['num_stopwords'] = feature_df['tokenized_text_nltk'].apply(lambda x: len([word for word in x if word in stop_words]))\n",
    "    feature_df['num_stopwords'] = feature_df['tokenized_text_spacy'].apply(lambda x: len([word for word in x if word in stop_words]))\n",
    "\n",
    "\n",
    "    #number of stopwords vs length of headline\n",
    "    feature_df['stopwords_vs_length'] = np.where(feature_df['headline_length'] > 0, feature_df['num_stopwords'] / feature_df['headline_length'], 0)\n",
    "\n",
    "    #number of stopwords vs words in headline\n",
    "    feature_df['stopwords_vs_words'] = np.where(feature_df['num_words'] > 0, feature_df['num_stopwords'] / feature_df['num_words'], 0)\n",
    "\n",
    "    #Exclamation Mark Features\n",
    "    # number of exclamation marks\n",
    "    feature_df['num_exclamation_marks'] = feature_df['headline'].apply(lambda x: x.count('!'))\n",
    "    #exclamation marks vs length of headline\n",
    "    feature_df['exclamation_vs_length'] = np.where(feature_df['headline_length'] > 0, feature_df['num_exclamation_marks'] / feature_df['headline_length'], 0)\n",
    "\n",
    "    #exclamation marks vs words\n",
    "    feature_df['exclamation_vs_words'] = np.where(feature_df['num_words'] > 0, feature_df['num_exclamation_marks'] / feature_df['num_words'], 0)\n",
    "\n",
    "    #Question Mark Features\n",
    "    # number of question marks\n",
    "    feature_df['num_question_marks'] = feature_df['headline'].apply(lambda x: x.count('?'))\n",
    "    #Question marks vs length of headline\n",
    "    feature_df['question_vs_length'] = np.where(feature_df['headline_length'] > 0, feature_df['num_question_marks'] / feature_df['headline_length'], 0)\n",
    "\n",
    "    #Question marks vs words\n",
    "    feature_df['question_vs_words'] = np.where(feature_df['num_words'] > 0, feature_df['num_question_marks'] / feature_df['num_words'], 0)\n",
    "\n",
    "\n",
    "    #Quotation Mark Features\n",
    "    # number of quotation marks\n",
    "    feature_df['num_quotation_marks'] = feature_df['headline'].apply(lambda x: x.count('\"'))\n",
    "    #Question marks vs length of headline\n",
    "    feature_df['quotation_vs_length'] = np.where(feature_df['headline_length'] > 0, feature_df['num_quotation_marks'] / feature_df['headline_length'], 0)\n",
    "\n",
    "    #Question marks vs words\n",
    "    feature_df['quotation_vs_words'] = np.where(feature_df['num_words'] > 0, feature_df['num_quotation_marks'] / feature_df['num_words'], 0)\n",
    "\n",
    "    #Single Quotation Mark Features\n",
    "    # number of quotation marks\n",
    "    feature_df['num_single_quotation_marks'] = feature_df['headline'].apply(lambda x: x.count(\"'\"))\n",
    "    #Question marks vs length of headline\n",
    "    feature_df['single_quotation_vs_length'] = np.where(feature_df['headline_length'] > 0, feature_df['num_single_quotation_marks'] / feature_df['headline_length'], 0)\n",
    "\n",
    "    #Question marks vs words\n",
    "    feature_df['single_quotation_vs_words'] = np.where(feature_df['num_words'] > 0, feature_df['num_single_quotation_marks'] / feature_df['num_words'], 0)\n",
    "\n",
    "    #Punctuation Mark Features\n",
    "    # number of punctuation marks\n",
    "    feature_df['num_punctuation_marks'] = feature_df['headline'].apply(get_punctuations)\n",
    "\n",
    "    #Punctuation marks vs length of headline\n",
    "    feature_df['punctuation_vs_length'] = np.where(feature_df['headline_length'] > 0, feature_df['num_punctuation_marks'] / feature_df['headline_length'], 0)\n",
    "\n",
    "    #Punctuation marks vs words\n",
    "    feature_df['punctuation_vs_words'] = np.where(feature_df['num_words'] > 0, feature_df['num_punctuation_marks'] / feature_df['num_words'], 0)\n",
    "\n",
    "    print('Creating Unique and Repeated word features')\n",
    "    unique_repeated = feature_df['headline_cleaned'].apply(get_unique_repeated)\n",
    "\n",
    "    feature_df['num_unique_words'] = unique_repeated.apply(lambda x: x[0])\n",
    "    feature_df['num_repeated_words'] = unique_repeated.apply(lambda x: x[1])\n",
    "\n",
    "    #Unique words vs length\n",
    "    feature_df['unique_vs_length'] = np.where(feature_df['headline_length'] > 0, feature_df['num_unique_words'] / feature_df['headline_length'], 0)\n",
    "\n",
    "    #Unique words vs words\n",
    "    feature_df['unique_vs_words'] = np.where(feature_df['num_words'] > 0, feature_df['num_unique_words'] / feature_df['num_words'], 0)\n",
    "\n",
    "    #Repeated words vs length\n",
    "    feature_df['repeated_vs_length'] = np.where(feature_df['headline_length'] > 0, feature_df['num_repeated_words'] / feature_df['headline_length'], 0)\n",
    "\n",
    "    #Unique words vs words\n",
    "    feature_df['repeated_vs_words'] = np.where(feature_df['num_words'] > 0, feature_df['num_repeated_words'] / feature_df['num_words'], 0)\n",
    "\n",
    "    #Word Tag Features\n",
    "    print('Creating POS Tag Features')\n",
    "    # word_tag = feature_df['pos_tagged_text_nltk'].apply(get_word_tag_count)\n",
    "    word_tag = feature_df['pos_tagged_text_spacy'].apply(get_word_tag_count)\n",
    "    feature_df['num_nouns'] = word_tag.apply(lambda x: x[0])\n",
    "    feature_df['num_adjectives'] = word_tag.apply(lambda x: x[1])\n",
    "    feature_df['num_verbs'] = word_tag.apply(lambda x: x[2])\n",
    "\n",
    "    #Nouns vs length\n",
    "    feature_df['nouns_vs_length'] = np.where(feature_df['headline_length'] > 0, feature_df['num_nouns'] / feature_df['headline_length'], 0)\n",
    "\n",
    "    #Nouns vs words\n",
    "    feature_df['nouns_vs_words'] = np.where(feature_df['num_words'] > 0, feature_df['num_nouns'] / feature_df['num_words'], 0)\n",
    "\n",
    "    #Adjectives vs length\n",
    "    feature_df['adjectives_vs_length'] = np.where(feature_df['headline_length'] > 0, feature_df['num_adjectives'] / feature_df['headline_length'], 0)\n",
    "\n",
    "    #Adjectives vs words\n",
    "    feature_df['adjectives_vs_words'] = np.where(feature_df['num_words'] > 0, feature_df['num_adjectives'] / feature_df['num_words'], 0)\n",
    "\n",
    "    #verbs vs length\n",
    "    feature_df['verbs_vs_length'] = np.where(feature_df['headline_length'] > 0, feature_df['num_verbs'] / feature_df['headline_length'], 0)\n",
    "\n",
    "    #verbs vs words\n",
    "    feature_df['verbs_vs_words'] = np.where(feature_df['num_words'] > 0, feature_df['num_verbs'] / feature_df['num_words'], 0)\n",
    "\n",
    "    #Readability, Sentiment Analysis\n",
    "    print('Creating Text Analysis features')\n",
    "    feature_df['readability'] = feature_df['headline'].apply(readability)\n",
    "    feature_df['sentiment'] = feature_df['headline'].apply(sentiment)\n",
    "\n",
    "    return feature_df"
   ],
   "id": "a76a470528b89403",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T15:15:01.210744Z",
     "start_time": "2025-03-09T15:12:54.005088Z"
    }
   },
   "cell_type": "code",
   "source": "feature_df = add_features(processed_df)",
   "id": "27967ea84a542e65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Length of headline\n",
      "Creating Word Features\n",
      "Creating Stopword features\n",
      "Creating Unique and Repeated word features\n",
      "Creating POS Tag Features\n",
      "Creating Text Analysis features\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T15:15:04.289708Z",
     "start_time": "2025-03-09T15:15:04.265868Z"
    }
   },
   "cell_type": "code",
   "source": "feature_df.head()",
   "id": "dd965a8cca10a934",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            headline  is_sarcastic  \\\n",
       "0  former versace store clerk sues over secret 'b...             0   \n",
       "1  the 'roseanne' revival catches up to our thorn...             0   \n",
       "2  mom starting to fear son's web series closest ...             1   \n",
       "3  boehner just wants wife to listen, not come up...             1   \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0   \n",
       "\n",
       "                                    headline_cleaned  \\\n",
       "0  former versace store clerk sues over secret bl...   \n",
       "1  the roseanne revival catches up to our thorny ...   \n",
       "2  mom starting to fear sons web series closest t...   \n",
       "3  boehner just wants wife to listen not come up ...   \n",
       "4  jk rowling wishes snape happy birthday in the ...   \n",
       "\n",
       "                                tokenized_text_spacy  \\\n",
       "0  [former, versace, store, clerk, sues, over, se...   \n",
       "1  [the, roseanne, revival, catches, up, to, our,...   \n",
       "2  [mom, starting, to, fear, sons, web, series, c...   \n",
       "3  [boehner, just, wants, wife, to, listen, not, ...   \n",
       "4  [jk, rowling, wishes, snape, happy, birthday, ...   \n",
       "\n",
       "                               pos_tagged_text_spacy  \\\n",
       "0  [(former, JJ), (versace, NN), (store, NN), (cl...   \n",
       "1  [(the, DT), (roseanne, NNP), (revival, NNP), (...   \n",
       "2  [(mom, NN), (starting, VBG), (to, TO), (fear, ...   \n",
       "3  [(boehner, NN), (just, RB), (wants, VBZ), (wif...   \n",
       "4  [(jk, NNP), (rowling, NNP), (wishes, VBZ), (sn...   \n",
       "\n",
       "                               lemmatized_text_spacy  headline_length  \\\n",
       "0  [former, versace, store, clerk, sue, over, sec...               78   \n",
       "1  [the, roseanne, revival, catch, up, to, our, t...               84   \n",
       "2  [mom, start, to, fear, son, web, series, close...               79   \n",
       "3  [boehner, just, want, wife, to, listen, not, c...               84   \n",
       "4  [jk, rowling, wish, snape, happy, birthday, in...               64   \n",
       "\n",
       "   num_words  num_words_vs_length  length_vs_num_words  ...  num_adjectives  \\\n",
       "0         12             0.153846             6.500000  ...               3   \n",
       "1         14             0.166667             6.000000  ...               4   \n",
       "2         14             0.177215             5.642857  ...               1   \n",
       "3         13             0.154762             6.461538  ...               1   \n",
       "4         11             0.171875             5.818182  ...               2   \n",
       "\n",
       "   num_verbs  nouns_vs_length  nouns_vs_words  adjectives_vs_length  \\\n",
       "0          1         0.076923        0.500000              0.038462   \n",
       "1          1         0.035714        0.214286              0.047619   \n",
       "2          4         0.063291        0.357143              0.012658   \n",
       "3          3         0.047619        0.307692              0.011905   \n",
       "4          1         0.078125        0.454545              0.031250   \n",
       "\n",
       "   adjectives_vs_words  verbs_vs_length  verbs_vs_words  readability  \\\n",
       "0             0.250000         0.012821        0.083333    67.755000   \n",
       "1             0.285714         0.011905        0.071429    77.810714   \n",
       "2             0.071429         0.050633        0.285714    83.853571   \n",
       "3             0.076923         0.035714        0.230769    71.767857   \n",
       "4             0.181818         0.015625        0.090909    85.888864   \n",
       "\n",
       "   sentiment  \n",
       "0     0.0000  \n",
       "1    -0.3182  \n",
       "2    -0.4939  \n",
       "3     0.0000  \n",
       "4     0.6486  \n",
       "\n",
       "[5 rows x 45 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline_cleaned</th>\n",
       "      <th>tokenized_text_spacy</th>\n",
       "      <th>pos_tagged_text_spacy</th>\n",
       "      <th>lemmatized_text_spacy</th>\n",
       "      <th>headline_length</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_words_vs_length</th>\n",
       "      <th>length_vs_num_words</th>\n",
       "      <th>...</th>\n",
       "      <th>num_adjectives</th>\n",
       "      <th>num_verbs</th>\n",
       "      <th>nouns_vs_length</th>\n",
       "      <th>nouns_vs_words</th>\n",
       "      <th>adjectives_vs_length</th>\n",
       "      <th>adjectives_vs_words</th>\n",
       "      <th>verbs_vs_length</th>\n",
       "      <th>verbs_vs_words</th>\n",
       "      <th>readability</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "      <td>former versace store clerk sues over secret bl...</td>\n",
       "      <td>[former, versace, store, clerk, sues, over, se...</td>\n",
       "      <td>[(former, JJ), (versace, NN), (store, NN), (cl...</td>\n",
       "      <td>[former, versace, store, clerk, sue, over, sec...</td>\n",
       "      <td>78</td>\n",
       "      <td>12</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>67.755000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "      <td>the roseanne revival catches up to our thorny ...</td>\n",
       "      <td>[the, roseanne, revival, catches, up, to, our,...</td>\n",
       "      <td>[(the, DT), (roseanne, NNP), (revival, NNP), (...</td>\n",
       "      <td>[the, roseanne, revival, catch, up, to, our, t...</td>\n",
       "      <td>84</td>\n",
       "      <td>14</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>77.810714</td>\n",
       "      <td>-0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "      <td>mom starting to fear sons web series closest t...</td>\n",
       "      <td>[mom, starting, to, fear, sons, web, series, c...</td>\n",
       "      <td>[(mom, NN), (starting, VBG), (to, TO), (fear, ...</td>\n",
       "      <td>[mom, start, to, fear, son, web, series, close...</td>\n",
       "      <td>79</td>\n",
       "      <td>14</td>\n",
       "      <td>0.177215</td>\n",
       "      <td>5.642857</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.012658</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.050633</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>83.853571</td>\n",
       "      <td>-0.4939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "      <td>boehner just wants wife to listen not come up ...</td>\n",
       "      <td>[boehner, just, wants, wife, to, listen, not, ...</td>\n",
       "      <td>[(boehner, NN), (just, RB), (wants, VBZ), (wif...</td>\n",
       "      <td>[boehner, just, want, wife, to, listen, not, c...</td>\n",
       "      <td>84</td>\n",
       "      <td>13</td>\n",
       "      <td>0.154762</td>\n",
       "      <td>6.461538</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>71.767857</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "      <td>jk rowling wishes snape happy birthday in the ...</td>\n",
       "      <td>[jk, rowling, wishes, snape, happy, birthday, ...</td>\n",
       "      <td>[(jk, NNP), (rowling, NNP), (wishes, VBZ), (sn...</td>\n",
       "      <td>[jk, rowling, wish, snape, happy, birthday, in...</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>5.818182</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>85.888864</td>\n",
       "      <td>0.6486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T15:09:49.273808Z",
     "start_time": "2025-03-09T15:09:49.263456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# feature_df_nltk = feature_df[['headline',\n",
    "#  'headline_cleaned',\n",
    "#  'tokenized_text_nltk',\n",
    "#  'pos_tagged_text_nltk',\n",
    "#  'lemmatized_text_nltk',\n",
    "#  'headline_length',\n",
    "#  'num_words',\n",
    "#  'num_words_vs_length',\n",
    "#  'length_vs_num_words',\n",
    "#  'num_stopwords',\n",
    "#  'stopwords_vs_length',\n",
    "#  'stopwords_vs_words',\n",
    "#  'num_exclamation_marks',\n",
    "#  'exclamation_vs_length',\n",
    "#  'exclamation_vs_words',\n",
    "#  'num_question_marks',\n",
    "#  'question_vs_length',\n",
    "#  'question_vs_words',\n",
    "#  'num_quotation_marks',\n",
    "#  'quotation_vs_length',\n",
    "#  'quotation_vs_words',\n",
    "#  'num_single_quotation_marks',\n",
    "#  'single_quotation_vs_length',\n",
    "#  'single_quotation_vs_words',\n",
    "#  'num_punctuation_marks',\n",
    "#  'punctuation_vs_length',\n",
    "#  'punctuation_vs_words',\n",
    "#  'num_unique_words',\n",
    "#  'num_repeated_words',\n",
    "#  'unique_vs_length',\n",
    "#  'unique_vs_words',\n",
    "#  'repeated_vs_length',\n",
    "#  'repeated_vs_words',\n",
    "#  'num_nouns',\n",
    "#  'num_adjectives',\n",
    "#  'num_verbs',\n",
    "#  'nouns_vs_length',\n",
    "#  'nouns_vs_words',\n",
    "#  'adjectives_vs_length',\n",
    "#  'adjectives_vs_words',\n",
    "#  'verbs_vs_length',\n",
    "#  'verbs_vs_words',\n",
    "#  'readability',\n",
    "#  'sentiment',\n",
    "# 'is_sarcastic']]"
   ],
   "id": "949b3f642d62ef9a",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T15:15:13.214205Z",
     "start_time": "2025-03-09T15:15:13.175630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "feature_df_spacy = feature_df[['headline',\n",
    " 'headline_cleaned',\n",
    " 'tokenized_text_spacy',\n",
    " 'pos_tagged_text_spacy',\n",
    " 'lemmatized_text_spacy',\n",
    " 'headline_length',\n",
    " 'num_words',\n",
    " 'num_words_vs_length',\n",
    " 'length_vs_num_words',\n",
    " 'num_stopwords',\n",
    " 'stopwords_vs_length',\n",
    " 'stopwords_vs_words',\n",
    " 'num_exclamation_marks',\n",
    " 'exclamation_vs_length',\n",
    " 'exclamation_vs_words',\n",
    " 'num_question_marks',\n",
    " 'question_vs_length',\n",
    " 'question_vs_words',\n",
    " 'num_quotation_marks',\n",
    " 'quotation_vs_length',\n",
    " 'quotation_vs_words',\n",
    " 'num_single_quotation_marks',\n",
    " 'single_quotation_vs_length',\n",
    " 'single_quotation_vs_words',\n",
    " 'num_punctuation_marks',\n",
    " 'punctuation_vs_length',\n",
    " 'punctuation_vs_words',\n",
    " 'num_unique_words',\n",
    " 'num_repeated_words',\n",
    " 'unique_vs_length',\n",
    " 'unique_vs_words',\n",
    " 'repeated_vs_length',\n",
    " 'repeated_vs_words',\n",
    " 'num_nouns',\n",
    " 'num_adjectives',\n",
    " 'num_verbs',\n",
    " 'nouns_vs_length',\n",
    " 'nouns_vs_words',\n",
    " 'adjectives_vs_length',\n",
    " 'adjectives_vs_words',\n",
    " 'verbs_vs_length',\n",
    " 'verbs_vs_words',\n",
    " 'readability',\n",
    " 'sentiment',\n",
    "'is_sarcastic']]"
   ],
   "id": "c711e1fbff29dd57",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T15:15:15.952206Z",
     "start_time": "2025-03-09T15:15:15.311447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# feature_df_nltk.to_csv('data/features_nltk.csv', index=False)\n",
    "feature_df_spacy.to_csv('data/features_spacy.csv', index=False)\n"
   ],
   "id": "958cc1dbe21f3cee",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9be012ce3323ff25"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
