{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def calculate_metrics(df):\n",
    "    y_true = df['is_sarcastic']\n",
    "    y_pred = df['prediction']\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Evaluate JSONL predictions.')\n",
    "    parser.add_argument('file_path', type=str, help='Path to the JSONL file')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    df = load_jsonl(args.file_path)\n",
    "    metrics = calculate_metrics(df)\n",
    "    \n",
    "    for metric, value in metrics.items():\n",
    "        print(f'{metric}: {value:.4f}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
